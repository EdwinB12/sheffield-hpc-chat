{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: https://example.com\n",
      "Content: <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>...\n",
      "Source: https://example.com\n",
      "Content: <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>Earlier this year the RSE team in Sheffield put a call out for proposals for researchers in the University of Sheffield to\\n<a href=\"https://rse.shef.ac.uk/collaboration/RSEtime_call2024/\">collaborate with the RSE</a> team. The successful applicants would receive dedicated support from an RSE\\nTeam member at 50% FTE for a period of six months.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>A total of 26 applications were received from across the faculties of the University and the review panel which\\nconsisted of nine RSEs had robust discussions about which to fund as the quality and proposed work was of a high\\nstandard.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p><img alt=\"Distribution of applications by faculty\" src=\"/assets/images/2024-09-24-funded-proposals-faculty.png\"/></p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>In the end the RSE team was able to fund support for three proposals and team members <a href=\"https://rse.shef.ac.uk/contact/robert-chisholm/\">Dr Robert Chisholm</a> and <a href=\"https://rse.shef.ac.uk/contact/neil-shephard/\">Neil\\nShephard</a> are about to start work on two of the projects with the third postponed, with agreement, until a new RSE\\nwho has been recruited starts later in the year.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>All work undertaken will be done with a view to adhering to the <a href=\"https://rse.shef.ac.uk/training/fair4rs/\">FAIR for Research Software Principles</a></p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>The <a href=\"https://www.sudlab.co.uk/team-1/ian-sudbery\">SubLab</a>, which is lead by <a href=\"https://www.sheffield.ac.uk/biosciences/academic-staff/people/ian-sudbery\">Dr Ian Subery</a>, have developed software to analyse the output of SLAMSeq\\nexperiments which performs sequence alignment of variably spliced RNA sequences to assess degradation rates. Despite\\nwide adoption of the technique the current software is limited to only being run on a per-gene basis rather than per\\nisoform basis and statistical comparison of differences in decay rates are limited. The <a href=\"https://www.sudlab.co.uk/team-1/ian-sudbery\">Sudlab</a> have addressed\\nthis deficiency by developing an analysis pipeline with pre-processing performed in Python and statistical analysis\\nundertaken in R.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>RSE support will be used to refactor the code into formal packages with a modular code structure and formal tests which\\nfacilitate long-term maintenance and make extension easier and will make it straight-forward for users to\\ninstall. Translation of code into a single language will be considered as this would lower the barrier to uptake by\\nexternal users and documentation will be developed and deployed covering the API and the practical side of using the\\nsoftware.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p><a href=\"https://github.com/gnomeCreative/HYBIRD\">HYBIRD</a> is software developed by <a href=\"https://www.sheffield.ac.uk/mac/people/civil-academic-staff/alessandro-leonardi\">Dr Alessandro Leonardi</a> and his research group with the\\nGeo-Technical Engineering group and is written using C++. It combines the Discrete Element Method (DEM) and the Lattice\\nBoltzmann Method (LBM) to simulate complex particle-fluid interactions. These fluid-structure interactions have\\nallowed the investigation of the formation of granular fronts in free-surface flows, enhancing understanding of\\nparticle-laden flow dynamics which have been successfully applied to key areas in environmental and geo-technical\\nengineering.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>Work will be undertaken by <a href=\"https://rse.shef.ac.uk/contact/robert-chisholm/\">Dr Robert Chisholm</a>, a performance optimisation and GPU parallelisation specialist from\\nour team, to modernise HYBIRD’s build system, address the limiting factors of its performance and enable it to take\\nadvantage of GPU parallelisation. The broad objectives of this project are to reduce barriers to entry for new users and\\nto increase the performance to enable faster and larger research experiments.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p><a href=\"https://github.com/bryonymoody/PolyChron\">Polychron</a> is prototype software developed by <a href=\"https://www.sheffield.ac.uk/mps/people/all-academic-staff/bryony-moody\">Dr Bryony Moody</a> of the School of Mathematical and\\nPhysical Sciences that facilitates the analysis and archiving of archaeological dating evidence. Written in Python the\\nprototype consists of a statistical algorithm (backend) and a GUI frontend to facilitate usage.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>Work will be undertaken by a new RSE who will be starting later in the year. The exact remit of the work to be\\nundertaken has not yet been finalised but the code base will benefit from restructuring into a Python package with\\nrefactoring of the GUI to make it easier to maintain and extend and improved error detection.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>As the number of applications demonstrated, the demand for RSE support across all faculties within the University is\\nhigh and it was interesting to find out about the broad range of software projects being undertaken by different\\nresearch groups. We wish we could have supported more of these teams.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>If you are considering putting in a funding application that involves writing/developing/maintaining software\\nhaving dedicated RSE support can strengthen your proposal. If you would like to speak to the RSE team about support\\nplease don’t hesitate to get in touch by emailing <a href=\"mailto:rse@sheffield.ac.uk\">rse@sheffield.ac.uk</a>.</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>\\n                For queries relating to collaborating with the RSE team on projects: <a href=\"mailto:rse@sheffield.ac.uk\">rse@sheffield.ac.uk</a>\\n</p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>\\n                Information and access to <a href=\"https://docs.hpc.shef.ac.uk/en/latest/other-uk-hpc-resources/jade2.html\">JADE II</a> and <a href=\"https://docs.hpc.shef.ac.uk/en/latest/other-uk-hpc-resources/bede.html\">Bede</a>.                \\n            </p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>\\n                Join our mailing list so as to be notified when we advertise talks and workshops by \\n                <a href=\"https://groups.google.com/a/sheffield.ac.uk/g/rse-group\">subscribing to this Google Group</a>.\\n            </p>'),\n",
       " Document(metadata={'source': 'https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/'}, page_content='<p>\\n\\t\\tQueries regarding free research computing support/guidance should be raised via our <a href=\"/support/code-clinic/\">Code clinic</a> or \\n\\t\\tdirected to the <a href=\"https://www.sheffield.ac.uk/nap/service/redirect/helpdesks\">University IT helpdesk</a>.\\n            </p>')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema import Document\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class CustomWebBaseLoader(WebBaseLoader):\n",
    "    def __init__(self, url: str):\n",
    "        super().__init__(url)\n",
    "        self.url = url\n",
    "\n",
    "    def load(self):\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(self.url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Remove unwanted sections: header, footer, etc.\n",
    "        for header in soup.find_all(['header', 'footer']):\n",
    "            header.decompose()  # Remove these sections from the soup\n",
    "\n",
    "        # Now parse the remaining content\n",
    "        paragraphs = soup.find_all('p')  # Or any other tag you're interested in\n",
    "        documents = []\n",
    "\n",
    "        for p in paragraphs:\n",
    "            # Creating a Document instance for each paragraph or relevant content\n",
    "            doc = Document(\n",
    "                page_content=str(p),  # The content of the paragraph\n",
    "                metadata={\"source\": self.url}  # Optional metadata (e.g., the source URL)\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "        return documents\n",
    "\n",
    "# Example usage:\n",
    "loader = CustomWebBaseLoader(\"https://example.com\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Print out the documents\n",
    "for doc in documents:\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")  # Preview first 200 characters\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "loader = CustomWebBaseLoader(\"https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/\")\n",
    "docs = loader.load()\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and chunk contents of the blog\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/\",\n",
    "#                )\n",
    "# )\n",
    "\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://rse.shef.ac.uk/blog/2024-09-24-funded-proposals/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=250, separators=[\".\"])\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull('rlm/rag-prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    #scores: List[float]\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State) -> List[Document]:\n",
    "    # docs, scores = vector_store.similarity_search_with_score(query)\n",
    "    # for doc, score in zip(docs, scores):\n",
    "    #     doc.metadata[\"score\"] = score\n",
    "\n",
    "    docs_and_scores = vector_store.similarity_search_with_score(state['question'])\n",
    "\n",
    "    # add score to doc metadata\n",
    "    for doc, score in docs_and_scores:\n",
    "        doc.metadata['score'] = score  \n",
    "\n",
    "    docs = [doc for doc, _ in docs_and_scores]\n",
    "    return {\"context\": docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the names of specific projects mentioned in the blog. The text mentions software developed by SubLab, but it does not provide a list of project names. It also mentions JADE II and Bede, which appear to be HPC resources, but these are not projects.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What are the names of the projects talked about in this blog?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
